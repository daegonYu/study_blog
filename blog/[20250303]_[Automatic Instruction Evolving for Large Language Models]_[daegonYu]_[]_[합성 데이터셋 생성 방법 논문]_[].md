# Automatic Instruction Evolving for Large Language Models
<br>
https://arxiv.org/html/2406.00770v1#bib.bib29
<br>

![image](https://github.com/user-attachments/assets/00ab5bb8-32ac-4c0d-9070-2e4e5ccfa762)


논문 **"Automatic Instruction Evolving for Large Language Models"**(Weihao Zeng et al., Microsoft)의 핵심 내용을 쉽게 이해할 수 있도록 설명해드리겠습니다.

---

## **1. 논문의 주요 내용**

### **기존 문제점**

- 대형 언어 모델(LLM)을 효과적으로 학습시키려면, 높은 품질의 **Instruction-following 데이터**가 필요합니다.
- **Evol-Instruct** 방법(기존 연구)에서는 사람이 규칙을 설계하여 데이터를 발전시키는 방식으로 동작합니다.
- 하지만, 새로운 작업(Task)에 적용하려면 **매번 새로운 규칙을 설계해야 하고, 전문가의 개입이 필요**하므로 **확장성이 제한적**입니다.

### **논문의 핵심 기여**

- **Auto Evol-Instruct**: LLM이 **자동으로** 학습 데이터를 더 복잡하고 다채롭게 변형하는 방법을 학습하는 **자동화된 프레임워크**를 제안합니다.
- 사람의 개입 없이 LLM이 스스로 **최적의 Instruction Evolving 방법**을 찾아내도록 설계되었습니다.
- 기존 수작업으로 설계된 방법(Evol-Instruct)보다 성능이 더 뛰어난 Instruction 데이터를 생성할 수 있음을 실험적으로 검증했습니다.

---

## **2. Auto Evol-Instruct의 동작 원리**

Auto Evol-Instruct는 두 가지 주요 LLM을 활용합니다.

1. **Evol LLM**: 실제 데이터를 변형시키는 역할
2. **Optimizer LLM**: Evol LLM이 생성한 데이터를 분석하고, **더 나은 변형 방법을 설계**하는 역할

### **자동화 과정**

1. **초기 변형 방법 설계 (Initial Evolving Method Design)**
    - 사람이 직접 규칙을 설계하는 대신, **Evol LLM이 데이터를 분석하여** 스스로 변형 규칙을 생성함.
    - 예를 들어, "더 어려운 문제를 만들기", "논리적 단계를 더 추가하기" 등의 방식으로 데이터를 복잡하게 변형.
2. **Evol Trajectory Analysis (변형 과정 분석)**
    - Evol LLM이 변형한 데이터를 Optimizer LLM이 분석하여, 문제가 있는지 점검.
    - 예를 들어, "생성된 데이터가 너무 단순함" 또는 "논리적으로 말이 안됨" 같은 오류를 찾아냄.
3. **Evolving Method Optimization (변형 방법 최적화)**
    - Optimizer LLM이 분석 결과를 바탕으로 변형 규칙을 개선.
    - 이 과정을 반복하면서 **점점 더 효과적인 변형 방법**을 찾아냄.
4. *최적의 변형 방법(e) 찾기*
    - 위 과정을 반복한 후, 가장 좋은 변형 방법을 찾으면 이를 전체 데이터에 적용하여 **최종 학습 데이터 생성**.

---

## **3. 실험 결과**

Auto Evol-Instruct는 **사람이 설계한 방법보다 더 좋은 데이터 변형을 수행할 수 있음**을 실험적으로 검증했습니다.

### **주요 성능 비교**

| 모델 | Instruction Following (MT-Bench) | 수학 (GSM8K) | 코드 생성 (HumanEval) |
| --- | --- | --- | --- |
| 기존 데이터 (Seed Data) | 6.88 | 56.90 | 57.90 |
| 기존 Evol-Instruct | 6.80 (-0.08) | 63.15 (+6.25) | 61.59 (+3.69) |
| **Auto Evol-Instruct (제안 방법)** | **7.51 (+0.63)** | **70.74 (+13.84)** | **65.85 (+7.95)** |

✅ **기존 방식보다 성능 향상됨**

✅ **더 적은 데이터로도 GPT-3.5-Turbo 수준의 성능 도달**

---

## **4. 논문의 핵심 포인트 정리**

- **기존 문제**: Instruction 데이터 변형을 위해 사람이 직접 규칙을 설계해야 했음 → **비효율적**
- **제안 방법**: Auto Evol-Instruct → LLM이 스스로 **최적의 변형 방법을 찾아냄**
- **자동화 과정**: ① 초기 규칙 생성 → ② 변형 과정 분석 → ③ 규칙 최적화 → ④ 최적 규칙 찾기
- **결과**: Auto Evol-Instruct가 **사람이 만든 방법보다 우수한 성능**을 보이며, 더 효율적으로 데이터를 발전시킴.

---

## **5. 연구의 의미와 한계**

### **의미**

- Instruction 데이터를 **자동으로** 발전시키는 방법을 개발하여, **새로운 작업에도 쉽게 확장 가능**.
- **Evol-Instruct보다 성능이 뛰어나고, 사람이 개입할 필요 없음**.
- **더 적은 데이터로도 GPT-3.5 수준 성능을 낼 수 있음** → 학습 비용 절감 가능.

### **한계**

- Optimizer LLM의 성능에 의존 → **최적화 과정이 지나치면 성능이 하락할 수도 있음**.
- 특정 Task(예: 코드 생성, 수학 문제 해결)에서만 검증됨 → **더 다양한 Task에 대한 확장 연구 필요**.

---

## **6. 결론**

Auto Evol-Instruct는 **LLM을 자동으로 발전시키는 방법을 찾아내는 프레임워크**로,

기존 방법보다 **더 적은 데이터로도 더 좋은 성능**을 낼 수 있다는 점에서 **혁신적인 연구**입니다. 🚀

✅ **Instruction Tuning 데이터 생성 자동화**

✅ **LLM의 활용 범위를 확장**

✅ **사람이 직접 규칙을 설계할 필요 없음**

**즉, 미래의 LLM 학습 방식이 "사람이 데이터를 설계하는 방식"에서 "모델이 스스로 데이터를 설계하는 방식"으로 진화하는 중요한 연구라고 볼 수 있습니다!** 😃

---

# Details

## **3.2 Evol Trajectory Analysis (진화 과정 분석)**

Auto Evol-Instruct의 목표는 **최적의 Instruction 데이터 변형 방법을 찾는 것**입니다.

이 과정에서 **Optimizer LLM**이 핵심 역할을 합니다.

### **✅ 핵심 개념**

- **Optimizer LLM**: Evol LLM이 수행한 데이터 변형을 분석하여 문제점을 찾고 피드백을 제공합니다.
- 변형 과정에서 잘못된 점을 찾아, 다음 변형 과정에서 개선할 수 있도록 합니다.

### **✅ Evol Trajectory (진화 경로)**

1. **초기 데이터 집합** Xt를 Evol LLM이 변형하기 시작.
2. Evol LLM이 **l번의 변형**을 수행하여 새로운 데이터셋을 생성:
St={Xt,Xt(1),Xt(2),...,Xt(l)}
    - Xt(i)는 **이전 데이터 Xt(i−1)을 Evol LLM이 변형한 결과**.
3. **Optimizer LLM**이 이 변형 과정(진화 경로)을 분석하여 **문제점을 찾고 피드백 ftf_tft 제공**.
    - 예: **"진화된 데이터가 충분히 복잡하지 않음"**, **"논리적 오류 발생"** 등 문제를 탐색.

즉, Evol LLM이 데이터를 변형하면 **Optimizer LLM이 그 변형이 제대로 되었는지 점검하는 역할**을 합니다.

---

## **3.3 Evolving Method Optimization (변형 방법 최적화)**

### **✅ 핵심 개념**

- **Optimizer LLM**이 제공한 피드백을 이용하여 변형 방법을 개선하는 과정.
- 최적화된 변형 방법을 찾아 **점점 더 나은 데이터셋을 생성할 수 있도록 함**.

### **✅ 과정**

1. **피드백 활용**: 이전 변형 방법 et−1을 피드백 ft을 반영하여 개선.
2. **새로운 변형 방법 생성**: 최적화된 변형 방법 et를 생성.
3. **반복 수행**: 여러 번 최적화를 거쳐 점점 더 나은 방법을 찾음.

---

### **✅ Multiple Optimizations (다중 최적화)**

Optimizer LLM이 항상 **완벽한 피드백을 제공하는 것은 아님**.

→ 따라서 **여러 개의 후보 변형 방법을 만들어 가장 좋은 방법을 선택하는 전략**을 사용합니다.

1. **각 최적화 단계에서 여러 개의 개선된 변형 방법** et1,et2,...,etm을 생성.
2. **각 방법을 실제로 적용하여 변형된 데이터셋을 평가**.
3. **가장 실패율(λ)이 낮은 변형 방법을 선택**:

    
    ![image.png](attachment:f314f752-6cbb-441a-aff5-8768f9b0ba40:image.png)
    
    - F(r) = 변형이 실패했으면 1, 성공했으면 0.
    - D = 평가용 데이터셋.

### **✅ 실패한 변형 예시**

- 모델이 단순히 **"Understood"** 또는 **"Thank you?"** 같은 응답을 하면 **변형이 실패한 것**으로 판단.
- 변형이 제대로 된 경우에는 **더 복잡한 질문이나 상세한 응답이 생성되어야 함**.

➡ **즉, 여러 개의 최적화된 변형 방법을 만든 후, 가장 성능이 좋은 방법을 선택하는 과정**.

---

## **3.4 Instruction Tuning on Evolved Data (진화된 데이터로 모델 학습)**

최적의 변형 방법 e∗이 결정되면, 이를 전체 데이터셋에 적용하여 **새로운 고품질 데이터셋을 생성**합니다.

1. **Evol LLM이 e∗을 사용하여 모든 Instruction 데이터를 진화시킴**.
2. **새로운 데이터셋으로 LLM을 다시 학습 (Fine-tuning)**.
3. 결과적으로 **더 나은 Instruction-following 모델을 구축**할 수 있음.

➡ **이 자동화된 방법을 통해, 더 좋은 Instruction 데이터셋을 만들고, 모델을 더욱 정교하게 학습할 수 있음**.

---

## **🔍 핵심 요약**

| 단계 | 설명 |
| --- | --- |
| **3.2 Evol Trajectory Analysis** | Evol LLM이 데이터를 변형하면, Optimizer LLM이 문제를 찾아 피드백 제공 |
| **3.3 Evolving Method Optimization** | 피드백을 바탕으로 변형 방법을 최적화 (다중 최적화 기법 사용) |
| **3.4 Instruction Tuning on Evolved Data** | 최적화된 방법을 전체 데이터에 적용 → LLM을 더 정교하게 학습 |

➡ **LLM이 스스로 학습 데이터를 개선하고, 이를 기반으로 성능을 점점 향상시키는 완전 자동화된 프레임워크!** 🚀

---

### **5.2 다중 최적화(Multiple Optimizations)의 효과 분석**

이 섹션에서는 **최적화 횟수(optimization steps)가 Auto Evol-Instruct의 성능에 미치는 영향을 분석**합니다.

---

## **✅ 실험 설정**

- **GSM8K 데이터셋**을 사용하여 최적화 횟수가 결과에 미치는 영향을 테스트.
- Auto Evol-Instruct의 기본 하이퍼파라미터를 유지하면서 **최적화 횟수(optimization steps)를 조절**.

---

## **✅ 실험 결과**

### **1. 최적화 횟수가 증가하면 성능이 향상됨**

- **최적화 횟수 1회** → GSM8K 성능 **62.7**
- **최적화 횟수 9회** → GSM8K 성능 **65.0**→ **최적화 횟수가 증가할수록 성능이 향상됨**.

**🔹 이유**

- 최적화 횟수가 늘어나면 **Optimizer LLM이 더 다양한 변형 방법을 탐색**할 수 있음.
- 즉, **더 나은 Instruction 변형 방법을 찾을 가능성이 커짐**.

---

### **2. 과도한 최적화는 성능 저하를 유발**

- Figure 5(b)에 따르면 **최적화 횟수가 12회를 초과하면 성능이 급격히 감소**.
- 즉, 일정 수준 이상 최적화를 반복하면 **오히려 성능이 저하됨**.

**🔹 이유**

- **Over-Optimization(과최적화)**:
    - 불필요한 정보가 Instruction 변형 방법에 축적되면서 **오히려 최적화 효과가 줄어듦**.
    - 최적화가 많아질수록 **Instruction이 과하게 복잡해지거나 불필요한 변화가 추가될 수 있음**.

---

## **✅ 최적화 횟수와 성능 간의 트레이드오프**

| 최적화 횟수 | 효과 |
| --- | --- |
| **1회** | 초기 성능(62.7), 최적화 부족 |
| **9회** | 최적 성능(65.0), 최적화 효과 극대화 |
| **12회 이상** | 성능 저하, 불필요한 정보 축적 |

➡ **최적의 최적화 횟수는 9회 정도**로 설정하는 것이 가장 좋은 결과를 가져옴.

➡ **최적화 횟수가 적으면?**

- 최적화가 충분히 이루어지지 않아 **국소 최적해(Local Optimum)에 갇힐 가능성**이 있음.
- 즉, 변형 방법이 개선되긴 하지만, **전반적으로 최상의 변형을 찾지 못할 가능성**이 있음.

➡ **최적화 횟수가 너무 많으면?**

- 연산 비용(Resource Consumption)이 증가하여 **학습 비용이 커짐**.
- 불필요한 정보가 누적되면서 **Instruction 변형이 비효율적으로 복잡해질 가능성**.

---

## **🔍 핵심 요약**

- 최적화 횟수가 **1에서 9로 증가하면 성능이 개선**됨.
- 하지만 **12회를 초과하면 성능이 저하**됨 (과최적화 문제).
- 따라서, **최적화 횟수를 적절히 조절하는 것이 중요**하며, **9회가 가장 효과적인 선택**임. 🚀

---

### **5.5 데이터셋의 복잡성과 다양성(Complexity and Diversity)의 중요성**

이 섹션에서는 **Instruction 데이터의 복잡성과 다양성이 모델 성능에 미치는 영향**을 분석합니다.

---

## **✅ 핵심 개념**

1. **데이터셋의 복잡성과 다양성이 증가하면 LLM의 성능이 향상된다.**
    - Liu et al. (2023b): 모델 정렬(Model Alignment)에 있어 데이터 복잡성과 다양성이 중요한 역할을 한다고 강조.
    - Instag Lu et al. (2023): 데이터 내 다양한 의도(Intentions)와 의미(Semantics)가 **데이터 복잡성과 다양성을 결정하는 핵심 요소**라고 주장.
2. **Auto Evol-Instruct가 데이터 복잡성과 다양성을 증가시키는지 실험을 통해 확인.**
    - **100개의 Instruction을 다양한 변형 기법을 이용해 진화(evolve)**.
    - **Instag의 자동 태깅(Auto-tagging) 기법을 사용하여 복잡성과 다양성을 평가**.
    - **평가 방법**:
        - **다양성(Diversity):** 각 데이터의 **고유 태그 수(Unique tags)의 평균값**.
        - **복잡성(Complexity):** **각 데이터의 태그 개수 평균값**.

---

## **✅ 실험 결과**

| 방법 | 다양성(Diversity) | 복잡성(Complexity) | HumanEval 성능 |
| --- | --- | --- | --- |
| **기존 Code Alpaca** | 1.95 | 4.06 | 57.9 |
| **Evol-Instruct** | 2.37 | 4.55 | 64.0 |

**➡ Evol-Instruct를 적용했을 때:**

- **다양성(Diversity)이 1.95 → 2.37로 증가**
- **복잡성(Complexity)이 4.06 → 4.55로 증가**
- **HumanEval 성능이 57.9 → 64.0으로 향상**

➡ **즉, 데이터의 다양성과 복잡성을 증가시키면 LLM의 성능이 향상됨을 확인!** 🚀

---

## **✅ 결론**

- **Instruction 데이터셋의 다양성과 복잡성을 증가시키면 모델 성능이 개선된다.**
- **Auto Evol-Instruct는 기존 Evol-Instruct보다도 데이터의 복잡성과 다양성을 효과적으로 높일 수 있다.**
- **다양하고 복잡한 데이터셋을 생성하면 LLM의 일반화 성능이 향상됨**.

**즉, 단순히 많은 데이터를 학습하는 것보다, "다양하고 복잡한 데이터"를 학습하는 것이 훨씬 더 효과적임을 입증한 실험!** 🚀

---

![image.png](attachment:a5df2ea7-5005-4046-95c5-894367df092c:image.png)

이미지에서 **"Prompt for Evol Trajectory Analysis"**라는 제목과 함께 **Optimizer LLM이 Instruction Evolution 과정에서 실패한 사례를 식별하는 프롬프트**가 포함되어 있습니다.

---

### **📌 이미지의 핵심 내용**

- **Evol Trajectory Analysis 프롬프트**는 Evol LLM이 수행한 Instruction 변형이 적절했는지 평가하는 과정에서 사용됩니다.
- **Optimizer LLM이 분석해야 할 요소**:
    1. **진화된 Instruction이 충분히 발전했는가?**
    2. **변형이 논리적이고 자연스러운가?**
    3. **진화 과정에서 실패한 경우를 식별할 수 있는가?**
- **프롬프트의 마지막 부분에 있는 문장 (주황색 텍스트)**
    
    *"Please identify cases that failed to evolve"*
    
    → Optimizer LLM에게 **진화에 실패한 사례를 식별하도록 요청**하는 부분.
    

---

### **📌 이 프롬프트의 역할**

- Evol LLM이 생성한 데이터 중 **제대로 변형되지 않았거나 복잡성이 증가하지 않은 경우**를 탐색.
- 이러한 실패 사례를 분석하여 **Evolving Method 최적화 과정(3.3절)에서 피드백을 제공**.
- 이후 **Multiple Optimizations(다중 최적화, 3.3절) 과정에서 더 나은 변형 방법을 찾아가는 데 활용**.

---

### **📌 결론**

이 프롬프트는 **Auto Evol-Instruct에서 Evol LLM이 수행한 변형이 적절했는지를 판단하는 핵심 요소**입니다.

Optimizer LLM이 실패 사례를 분석하고 이를 바탕으로 **Instruction Evolving 방법을 점진적으로 개선하는 과정에서 사용**됩니다. 🚀

---

![image.png](attachment:5935bf7b-0ddb-48be-8c77-fb84568f1ce8:image.png)

### **📌 이미지 분석: Prompt for Evolving Method Optimization**

---

## **✅ 핵심 내용**

이 이미지는 **Auto Evol-Instruct 프레임워크에서 "Evolving Method Optimization(변형 방법 최적화)" 단계에서 사용되는 프롬프트**를 보여줍니다.

- **프롬프트 제목**: "Prompt For Evolving Method Optimization"→ **Evol-Instruct 변형 방법을 최적화하기 위한 프롬프트**
- **프롬프트 내용**:*"You need to optimize this method based on the feedback from the evolution failure case."*→ **이전 단계(Evol Trajectory Analysis)에서 발생한 실패 사례를 기반으로 변형 방법을 최적화해야 함**.

---

## **✅ 역할 및 기능**

1. **진화 실패(Failure Case) 피드백 반영**
    - 이전 단계에서 **Optimizer LLM이 진화 실패 사례를 분석**했음.
    - 이제 이 정보를 활용하여 **Evolving Method를 개선하는 과정**.
2. **변형 방법의 지속적 개선**
    - Optimizer LLM이 기존 **Evol-Instruct 방법이 가진 한계를 파악**하고
    - **새로운 규칙을 추가하거나, 잘못된 규칙을 수정하는 방식으로 변형 방법을 최적화**.
3. *최적의 진화 방법(e) 찾기*
    - 이 과정을 반복하면 점점 더 나은 Instruction 변형 방법을 찾을 수 있음.
    - 최종적으로 **가장 낮은 실패율을 가진 최적의 변형 방법이 선택됨**.

---

## **✅ 전체 프로세스에서 이 프롬프트의 위치**

| 단계 | 설명 |
| --- | --- |
| **1. Evol LLM이 Instruction을 변형** | 데이터를 변형하여 새로운 Instruction 생성 |
| **2. Evol Trajectory Analysis (진화 분석)** | 변형된 데이터가 적절한지 검사, 실패 사례 분석 |
| **3. Evolving Method Optimization (변형 방법 최적화, 이 단계)** | 실패 사례를 기반으로 변형 방법을 개선 |
| **4. 반복 수행 → 최적의 변형 방법 찾기** | 성능이 가장 좋은 변형 방법을 최종 선택 |

---

## **✅ 결론**

- **이 프롬프트는 Auto Evol-Instruct가 지속적으로 발전할 수 있도록 하는 핵심 요소**.
- **실패 사례를 반영하여 Instruction 변형 방법을 점진적으로 개선하는 역할**.
- 이를 통해 **최종적으로 가장 효과적인 Instruction 변형 방법을 찾고, 모델 성능을 극대화할 수 있음**.

➡ **즉, "Evolving Method Optimization"은 Auto Evol-Instruct의 최적화를 위한 핵심 과정이며, 이 프롬프트를 통해 실패 사례를 반영한 지속적인 개선이 이루어짐!** 🚀
