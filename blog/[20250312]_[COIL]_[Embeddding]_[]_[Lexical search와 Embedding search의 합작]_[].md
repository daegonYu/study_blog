![image](https://github.com/user-attachments/assets/f96b5f5a-05f4-4629-8856-d05b3af911b6)

https://arxiv.org/abs/2104.07186

## 📌 **COIL 논문 핵심 요약**

COIL(Contextualized Inverted List)는 전통적인 **정확한 단어 일치(Exact Match)** 방식을 사용하는 검색 시스템(BM25 등)과, 딥러닝 기반의 **의미적 유사성(Semantic Matching)** 검색 시스템을 결합한 새로운 정보 검색(IR) 모델입니다.

기존 IR 방식의 문제점:

1. **BM25 같은 전통적 방법** → 단어가 정확히 일치해야 검색됨 (예: "cat"과 "kitty"는 다른 단어로 인식)
2. **딥러닝 기반의 의미적 검색** → 모든 단어를 비교하여 의미적 일치를 고려하지만, 계산량이 많아 속도가 느림

COIL은 **"문맥을 고려한 정확한 단어 일치 (Contextualized Exact Match)"** 라는 개념을 도입하여, 기존 검색 시스템의 효율성을 유지하면서도 딥러닝 모델의 의미적 표현력을 활용하는 모델입니다.

---

## 🔍 **COIL이 기존 모델과 다른 점**

1. **토큰 단위의 정확한 매칭을 유지하지만, 의미도 고려**
    - 기존 BM25처럼 단어가 정확히 일치하는 경우에만 검색하지만, 단순한 TF-IDF 스코어 대신 **딥러닝 기반 문맥 임베딩(Contextualized Representations)** 을 사용하여 더 정교한 유사도를 계산합니다.
2. **효율적인 검색 구조 (Inverted List 활용)**
    - 검색을 빠르게 수행하기 위해 **역색인(Inverted Index)** 을 활용합니다.
    - 예를 들어, 문서에서 "bank"라는 단어가 등장하면, 그 단어의 문맥 임베딩을 생성하여 미리 저장해 둡니다.
    - 검색 시에는 "bank"라는 단어를 포함하는 문서만 검색하되, 단어의 문맥 벡터를 비교하여 더 의미적으로 적절한 문서를 찾음.
3. **딥러닝 기반 Dense Retrieval보다 빠름**
    - 기존의 BERT 기반 Dense Retrieval 모델들은 문서 전체를 임베딩으로 변환하고, 검색할 때 전체 문서 벡터를 비교하는 방식이라 속도가 느립니다.
    - COIL은 **토큰 단위로 검색** 하므로, 의미적 유사성을 고려하면서도 효율적인 검색이 가능.

---

## 🎯 **쉽게 이해하는 COIL: 예제**

1️⃣ **BM25 방식 (기존 Exact Match)**

- 검색어: `"강아지"`
- 문서 1: `"귀여운 강아지"` ✅ (매칭됨)
- 문서 2: `"사랑스러운 댕댕이"` ❌ (단어가 다름)

2️⃣ **BERT 기반 Dense Retrieval (Semantic Matching)**

- 검색어: `"강아지"`
- 문서 1: `"귀여운 강아지"` ✅
- 문서 2: `"사랑스러운 댕댕이"` ✅ (BERT가 의미적으로 유사하다고 판단)

3️⃣ **COIL 방식 (Contextualized Exact Match)**

- 검색어 `"강아지"` 의 문맥 벡터를 생성하여 **일치하는 단어만 검색**하지만, 의미도 고려함.
- `"강아지"`라는 단어가 포함된 문서를 우선적으로 가져오되, 문맥을 비교하여 `"댕댕이"`와 같은 단어도 적절히 반영 가능.

---

## 🚀 **COIL의 주요 장점**

✅ **빠름** → 기존 검색 엔진(BM25)처럼 **역색인(inverted list)** 을 활용하여 효율적 검색

✅ **의미적 일치 가능** → BERT 같은 **딥러닝 임베딩 사용**, 단순 단어 일치가 아니라 문맥도 반영

✅ **설명 가능성** → 검색이 어떻게 이루어졌는지 명확히 해석 가능 (단어-문맥 벡터 비교 기반)

### 🎯 **결론**

COIL은 **전통적인 Exact Match 검색의 효율성과, 딥러닝 기반 의미적 검색의 장점을 결합** 한 모델입니다.

즉, **BM25처럼 빠르면서도, BERT처럼 의미적으로 정교한 검색이 가능** 합니다! 🚀

---

## 🔎 **1. 전통적인 Lexical Retrieval 시스템 (BM25 등)**

### 🏛️ **기존 방식: Exact Match 기반 검색**

- **대표적 모델**: BM25, Boolean Retrieval, 통계적 언어 모델
- **방식**: 문서를 **역색인(Inverted Index)** 으로 정리하여, 쿼리에 포함된 단어가 있는 문서만 빠르게 검색
- **문제점**:
    1. **어휘 불일치(Vocabulary Mismatch)**
        - 같은 개념이 다른 단어로 표현될 때 검색 실패 (예: `"강아지"` vs. `"댕댕이"`)
    2. **문맥 정보 부족(Semantic Mismatch)**
        - `"은행(bank)"`이 `"강가의 은행"`인지 `"금융 기관"`인지 구별할 수 없음
- **기존 해결책**:
    - n-gram 확장(Metzler and Croft, 2005)
    - 연관 단어로 쿼리 확장 (Lavrenko and Croft, 2001)
    - 하지만 **BOW(Bag-of-Words) 방식**을 유지하는 한 한계가 있음

---

## 🔎 **2. Neural Ranker (소프트 매칭 방식의 등장)**

### 🧠 **딥러닝 기반 검색의 시작**

- 단어 벡터(Word2Vec, GloVe 등)를 사용하여 단어 간 의미적 유사성을 고려한 검색 등장
- **방식**:
    1. 쿼리와 문서를 **하나의 벡터**로 변환 후 유사도를 계산 (Huang et al., 2013)
    2. 이후, **각 단어의 벡터를 개별적으로 비교하는 방식 (Full Interaction 모델)** 등장
- **문제점**:
    - 딥러닝을 사용할수록 계산량이 급증
    - 실제 검색에서는 속도가 너무 느려 **사전 검색 후 재정렬(Re-ranking)** 과정에서만 사용

---

## 🔎 **3. Deep LM 기반 랭커 및 검색 모델**

### 📌 **BERT 기반 Re-Ranker**

- **대표 모델**: BERT (Devlin et al., 2019)
- **방식**:
    - 쿼리와 문서를 BERT 모델에 입력하고, [CLS] 토큰의 출력을 이용하여 **관련도 점수**를 계산
    - 문맥을 고려한 **풀 크로스 어텐션 (Full Cross-Attention)** 을 수행
- **문제점**:
    - 계산량이 너무 많아 **실시간 검색에는 비효율적**

### 📌 **BM25 + Deep LM 조합 모델**

- **DocT5Query (Nogueira and Lin, 2019)**: 문서에 추가적인 단어를 생성하여 검색 가능성을 높임
- **DeepCT (Dai and Callan, 2019a)**: 문서에서 중요한 단어에 더 높은 가중치를 부여
- 하지만, 결국 **기본적인 단어 일치의 한계를 넘어서지 못함**

### 📌 **Dense Retrieval 모델 (딥러닝 기반 벡터 검색)**

- 문서 전체를 벡터로 변환하여 **최근접 이웃 검색 (Nearest Neighbor Search)** 을 수행
- 대표적인 Dense Retrieval 모델:
    - **DPR (Dense Passage Retrieval, Karpukhin et al., 2020)**
    - **ANCE (Xiong et al., 2020)**
- **한계**:
    - 문서 하나를 하나의 벡터로 변환하면, 문서 내의 세부적인 의미를 반영하기 어려움
    - 훈련 데이터가 많아야 성능이 잘 나옴

### 📌 **Multi-Vector Retrieval (문서 내 토큰별 벡터 사용)**

- 한 문서를 하나의 벡터로 표현하는 대신, **여러 개의 벡터로 나누어 표현**
- 대표적인 모델:
    - **Poly-Encoder (Humeau et al., 2020)**
    - **Me-BERT (Luan et al., 2020)**
    - **ColBERT (Khattab and Zaharia, 2020)**:
        - 문서의 **모든 단어를 벡터로 변환하여 검색**
        - "쿼리의 모든 단어" vs. "문서의 모든 단어" 간 유사도를 계산하는 **전수 비교(Cartesian Product)** 수행
        - 하지만 **인덱스 크기가 커지고, 계산량이 많아짐**

---

## 🔎 **COIL의 차별점**

COIL은 기존 방법들의 장점만을 가져와 **효율적이면서도 강력한 의미적 검색이 가능한 새로운 방식**을 제안합니다.

✅ **BM25처럼 빠른 검색 속도 유지** (역색인 사용)

✅ **BERT처럼 문맥을 고려한 검색 가능** (컨텍스트 임베딩 사용)

✅ **ColBERT보다 가벼운 모델 구조** (전체 문서가 아니라 특정 토큰만 저장)

💡 **즉, COIL은 전통적인 Exact Match 방식을 기반으로, 문맥을 고려한 벡터 비교를 추가하여 빠르면서도 의미적 검색이 가능한 모델!**

COIL은 기존 Lexical Retrieval의 빠른 검색 속도와, Dense Retrieval의 의미적 검색 성능을 모두 결합한 모델입니다.

즉, **BM25의 검색 효율성 + BERT의 의미적 검색력**을 동시에 활용하는 방식이라고 볼 수 있습니다.

---

## 1️⃣ **기존 Exact Match 검색 방식 (BM25 등)**

### 🏛️ **BM25와 같은 전통적 검색 모델의 구조**

전통적인 검색 시스템(예: BM25)은 **쿼리(Query)와 문서(Document)에서 겹치는 단어**를 기반으로 검색을 수행합니다.


- **이 방식의 장점**
    - **빠름** → 역색인(Inverted Index)을 사용하여 **쿼리에 해당하는 단어가 포함된 문서만 검색**
    - **설명 가능성** → 검색 점수가 어떻게 계산되었는지 해석 가능
- **하지만 문제점**
    1. **어휘 불일치 (Vocabulary Mismatch)**
        - 같은 의미라도 다른 단어면 검색되지 않음 (예: `"강아지"` vs. `"댕댕이"`)
    2. **문맥 정보 부족 (Semantic Mismatch)**
        - `"은행(bank)"`이 금융 기관인지 강가인지 구분할 수 없음

---

## 2️⃣ **COIL: Contextualized Exact Lexical Match**

COIL은 기존 Exact Match 방식을 유지하면서도, **단어의 문맥(Context)** 을 반영하여 검색 성능을 향상시킵니다.

### 🔍 **COIL의 핵심 개념: 문맥을 고려한 정확한 단어 일치 (Contextualized Exact Match)**

- BM25처럼 **쿼리와 문서에서 겹치는 단어만 검색**
- 하지만 **단순 빈도 기반 점수가 아니라, 단어의 문맥(Contextualized Representation)을 활용**
- 딥러닝(Transformer LM)을 사용하여 **각 단어의 의미를 벡터(Vector)로 변환**

---

## 3️⃣ **COIL의 검색 점수 계산 방식**

### **🔹 1단계: 토큰(Contextualized Token) 벡터 생성**

BM25에서는 단어 빈도를 기반으로 점수를 계산했지만, COIL에서는 단어의 의미를 반영하는 **문맥적 벡터(Contextualized Embedding)** 를 사용합니다.


---

### **🔹 2단계: 정확한 단어 일치 기반 벡터 비교**

BM25처럼 **쿼리와 문서에서 겹치는 단어만 비교**하지만, 단순 빈도가 아니라 **문맥 벡터 간 유사도**를 계산합니다.


- **핵심 아이디어**
    1. 쿼리의 각 단어 qi 에 대해 문서에서 동일한 단어 dj 찾기
    2. 해당 단어들의 **문맥 벡터(Contextualized Embeddings) 간 유사도**를 계산
    3. 가장 높은 유사도(Max Pooling)를 선택하여 점수 계산

✅ **BM25처럼 "겹치는 단어만 검색"하되, 단어의 의미까지 반영하는 방식!**

---

### **🔹 3단계: CLS 벡터를 활용한 의미적 유사성 보정**

COIL은 Exact Match 방식이기 때문에 여전히 어휘 불일치(Vocabulary Mismatch) 문제가 존재합니다.

이를 해결하기 위해, **쿼리와 문서 전체를 대표하는 CLS 벡터를 활용하여 의미적 유사성을 반영**합니다.

- **쿼리 및 문서 전체 의미 벡터 생성**
    - Transformer의 [CLS] 토큰을 사용하여 쿼리와 문서의 전체적인 의미를 벡터화
- **최종 검색 점수 계산 (COIL-Full)**
    - 기존 **토큰 단위 검색 점수**
    - 추가적으로 **쿼리-문서 전체 의미 벡터 유사도** 반영

✅ **즉, COIL은 "토큰 단위 문맥 매칭" + "전체 문맥 매칭"을 결합한 모델!**

---

## 4️⃣ **COIL 모델 학습 방식**

COIL은 **Negative Log Likelihood (NLL) 손실 함수**를 사용하여 학습됩니다.

- **양의 문서 (Positive Document)와 음의 문서 (Negative Document) 비교**
    - BM25에서 **Hard Negative Sampling** 을 통해 어려운 음성 데이터를 포함하여 학습 성능 향상

✅ **BM25의 Hard Negative + 문맥적 벡터 학습을 결합하여 검색 성능을 극대화!**

---

## 🎯 **결론: COIL이 기존 검색 모델과 다른 점**

| 모델 | 검색 방식 | 장점 | 단점 |
| --- | --- | --- | --- |
| **BM25** | Exact Match | 빠름, 효율적 | 어휘 불일치 문제 |
| **Dense Retriever (DPR, ANCE)** | 전체 문서 벡터화 후 최근접 이웃 검색 | 의미적 검색 가능 | 계산량 많음 |
| **ColBERT** | 문서의 모든 토큰 벡터화 후 비교 | 정교한 의미 검색 | 인덱스 크기 너무 큼 |
| **COIL** | Exact Match + Contextualized Embedding | 빠르면서도 의미적 검색 가능 | 일부 어휘 불일치 문제 |

✅ **COIL은 BM25처럼 빠르고, BERT처럼 의미적 검색이 가능한 하이브리드 모델!** 🚀
